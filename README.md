# ğŸ›ï¸ Futures Foundation Model (FFM)

**A pretrained transformer backbone for futures market structure and regime classification.**

---

## Overview

Futures Foundation Model (FFM) is an open-source pretrained transformer designed to learn **market structure** and **regime dynamics** from raw OHLCV futures data. The backbone learns general representations of market behavior that can be fine-tuned for any downstream trading strategy.

### Philosophy

> Separate **"understanding market context"** from **"making strategy-specific decisions."**

Just as BERT learns language structure before being fine-tuned for sentiment or Q&A, FFM learns market structure before being fine-tuned for ORB entries, ICT setups, mean reversion signals, or any other strategy.

---

## Architecture

```
Input: OHLCV Bars (sequence of N bars Ã— F derived features)
         â”‚
    [Instrument Embedding + Session Embedding + Temporal Encoding]
         â”‚
    [Transformer Encoder Ã— 6 layers]
      â€¢ Multi-head self-attention (8 heads)
      â€¢ Feed-forward network
      â€¢ LayerNorm + residual connections
      â€¢ Dropout regularization
         â”‚
    [Sequence Pooling] â† CLS token aggregation
         â”‚
    BACKBONE OUTPUT: Market Context Embedding (256-dim)
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”
 [Regime]  [Volatility]  [Structure]  [Range]    â† Pretraining heads
    â”‚
    â””â”€â”€â†’ Fine-tune: [ORB Head] [ICT Head] [Custom Head]
```

### Pretraining Objectives (Self-Supervised from OHLCV)

All labels are **derived automatically** from price data â€” no manual annotation required:

| Task | Classes | Description |
|------|---------|-------------|
| **Regime** | Trending Up, Trending Down, Rotational, Volatile Expansion | Market regime at sequence end |
| **Volatility State** | Low, Normal, Elevated, Extreme | ATR percentile vs rolling history |
| **Market Structure** | HH+HL (Bullish), LH+LL (Bearish), Mixed | Swing point structure |
| **Range Position** | 5 quintiles (0-20%, 20-40%, ..., 80-100%) | Price position in recent range |

---

## Quick Start

### Installation

```bash
git clone https://github.com/YOUR_USERNAME/futures-foundation-model.git
cd futures-foundation-model
pip install -e .
```

### Using the Pretrained Backbone

```python
from futures_foundation import FFMConfig, FFMForPretraining, FFMBackbone

# Load pretrained backbone
config = FFMConfig()
backbone = FFMBackbone(config)
backbone.load_pretrained("path/to/checkpoint")

# Get market context embeddings
embeddings = backbone(features_tensor)  # (batch, 256)
```

### Fine-Tuning for a Strategy

```python
from futures_foundation import FFMForClassification

# ORB strategy: BUY / SELL / HOLD
model = FFMForClassification(config, num_labels=3)
model.load_backbone("path/to/pretrained/backbone")
model.freeze_backbone(freeze_ratio=0.66)  # Freeze bottom 2/3

# Train only the top layers + classification head
optimizer = torch.optim.AdamW(model.trainable_parameters(), lr=1e-4)
```

---

## Data Preparation

### Supported Instruments
- **ES** (E-mini S&P 500)
- **NQ** (E-mini Nasdaq 100)
- **RTY** (E-mini Russell 2000)
- **YM** (E-mini Dow)
- Extensible to: GC (Gold), SI (Silver), CL (Crude Oil), and more

### Input Format

Place your OHLCV CSV files in `data/raw/`:

```
data/raw/
â”œâ”€â”€ ES_5min.csv
â”œâ”€â”€ NQ_5min.csv
â”œâ”€â”€ RTY_5min.csv
â””â”€â”€ YM_5min.csv
```

Each CSV should have columns: `datetime, open, high, low, close, volume`

### Feature Derivation & Label Generation

```bash
# Derive features, generate labels, and create sequences are handled
# automatically by the pretrain.py script. Just point it at your raw data:
python scripts/pretrain.py --data-dir data/raw/ --output-dir checkpoints/pretrained/
```

---

## Training

### Stage 1: Pretraining

```bash
python scripts/pretrain.py \
    --data-dir data/raw/ \
    --output-dir checkpoints/pretrained/ \
    --epochs 50 \
    --batch-size 256 \
    --lr 1e-3 \
    --seq-len 64
```

### Stage 2: Fine-Tuning (Example: ORB)

```bash
python scripts/finetune.py \
    --backbone checkpoints/pretrained/best_backbone.pt \
    --strategy orb \
    --data-dir data/orb_labeled/ \
    --output-dir checkpoints/orb/ \
    --freeze-ratio 0.66 \
    --epochs 30 \
    --lr 1e-4
```

---

## Project Structure

```
futures-foundation-model/
â”œâ”€â”€ futures_foundation/          # Core library
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py               # FFMConfig (HuggingFace compatible)
â”‚   â”œâ”€â”€ model.py                # Transformer backbone + heads
â”‚   â”œâ”€â”€ features.py             # OHLCV â†’ derived features
â”‚   â”œâ”€â”€ labels.py               # Auto-label generation
â”‚   â””â”€â”€ dataset.py              # PyTorch Dataset + DataLoader
â”œâ”€â”€ scripts/                    # Training & data prep scripts
â”‚   â”œâ”€â”€ pretrain.py
â”‚   â””â”€â”€ finetune.py
â”œâ”€â”€ configs/                    # Model & training configs
â”‚   â””â”€â”€ default.yaml
â”œâ”€â”€ tests/                      # Unit tests
â”‚   â””â”€â”€ test_model.py
â”œâ”€â”€ examples/                   # Usage examples
â”‚   â””â”€â”€ finetune_orb.py
â”œâ”€â”€ setup.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ CONTRIBUTING.md
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```

---

## Contributing

We welcome contributions! Key areas:

- **New instruments**: Add support for crypto, forex, commodities
- **Additional pretraining tasks**: Order flow proxies, session pattern recognition
- **Fine-tuning recipes**: Share configs for specific strategies
- **Feature engineering**: Novel OHLCV-derived features
- **Evaluation benchmarks**: Standardized regime classification benchmarks

See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

---

## Roadmap

- [x] Core transformer backbone with HuggingFace compatibility
- [x] OHLCV feature derivation pipeline (42 features)
- [x] Self-supervised label generation (4 tasks)
- [x] Pretraining script with multi-task uncertainty weighting
- [x] Fine-tuning framework with backbone freezing
- [ ] Pretrained weights release (ES, NQ, RTY, YM â€” 5 years)
- [ ] HuggingFace Hub integration (`from_pretrained`)
- [ ] Multi-timeframe input support
- [ ] Additional instruments (GC, SI, CL)
- [ ] Evaluation suite and benchmarks
- [ ] ONNX export for production inference

---

## License

Apache 2.0 â€” See [LICENSE](LICENSE) for details.

---

## Disclaimer

This software is for **research and educational purposes only**. It does not constitute financial advice. Trading futures involves substantial risk of loss. Past performance of any model does not guarantee future results.
